{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9741,
     "status": "ok",
     "timestamp": 1652650279113,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "CX5I_WCKp2Q_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/31 13:02:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/31 13:02:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/31 13:02:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Start Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Twitter_Sentiment_NLP\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 11842,
     "status": "ok",
     "timestamp": 1652650290952,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "z-m7GHX29YYO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read in data from S3 Buckets\n",
    "from pyspark import SparkFiles\n",
    "url =\"https://ilanp-bucket.s3.us-west-2.amazonaws.com/sentiment_analysis_10k.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "tweet_df = spark.read.csv(SparkFiles.get(\"sentiment_analysis_10k.csv\"), sep=\",\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1652650291453,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "49MzIZcws4C2",
    "outputId": "ac041a3a-4d5c-48bf-b831-9d499512c4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------+--------------+--------------------+--------+\n",
      "|polarity|        id|                date|   query|          user|                text|new_date|\n",
      "+--------+----------+--------------------+--------+--------------+--------------------+--------+\n",
      "|       0|2051199119|Fri Jun 05 21:04:...|NO_QUERY|    alicatpurr|My moonstone pend...|  6/5/09|\n",
      "|       0|2051199378|Fri Jun 05 21:04:...|NO_QUERY|      joshwehe|Watching baseball...|  6/5/09|\n",
      "|       0|2051200441|Fri Jun 05 21:05:...|NO_QUERY|    qwerkyqook|RIP cute black ma...|  6/5/09|\n",
      "|       0|2051201409|Fri Jun 05 21:05:...|NO_QUERY|       Lizfig3|@pandafandanga we...|  6/5/09|\n",
      "|       0|2051201881|Fri Jun 05 21:05:...|NO_QUERY|sweet_ctstrphe|lost my  voice  w...|  6/5/09|\n",
      "+--------+----------+--------------------+--------+--------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [\n",
    "    {\"polarity\": 1.0, \"label\" : 1.0, \"text\" : \"I am so happy to be here today!\"},\n",
    "    {\"polarity\" : 0.0,\"label\" : 0.0, \"text\" : \"Today is a terrible day.\"},\n",
    "    {\"polarity\" : 1.0,\"label\" : 1.0, \"text\" : \"I am so in love today!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+\n",
      "|label|polarity|                text|\n",
      "+-----+--------+--------------------+\n",
      "|  1.0|     1.0|I am so happy to ...|\n",
      "|  0.0|     0.0|Today is a terrib...|\n",
      "|  1.0|     1.0|I am so in love t...|\n",
      "+-----+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_df2 = spark.createDataFrame(list)\n",
    "#tweet_df2 = tweet_df\n",
    "tweet_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652650291453,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "nY_6T6XcqD4d"
   },
   "outputs": [],
   "source": [
    "# Import functions\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1652650292065,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "Ku5NvLq3qIqp",
    "outputId": "b2b6cc83-b59b-4e4a-f066-9cae221f808d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+------+\n",
      "|label|polarity|                text|length|\n",
      "+-----+--------+--------------------+------+\n",
      "|  1.0|     1.0|I am so happy for...|    63|\n",
      "|  0.0|     0.0|This sucks!  I do...|    39|\n",
      "+-----+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "# Create a length column to be used as a future feature\n",
    "data_df = tweet_df2.withColumn('length', length(tweet_df2['text']))\n",
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1652650292270,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "BJOVRU6dqP0-"
   },
   "outputs": [],
   "source": [
    "# Create all the features to the data set\n",
    "#pos_neg_to_num = StringIndexer(inputCol='polarity',outputCol='label')\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1652650292271,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "sr-jLVQPqZJ6"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "# Create feature vectors\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652650292271,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "50PgQeIZqnGT"
   },
   "outputs": [],
   "source": [
    "# Create and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7510,
     "status": "ok",
     "timestamp": 1652650299778,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "K1wefUeGqqAv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit and transform the pipeline\n",
    "cleaner = data_prep_pipeline.fit(data_df)\n",
    "cleaned = cleaner.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/31 12:59:57 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "22/05/31 12:59:57 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "22/05/31 12:59:57 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|polarity|                text|length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
      "+-----+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1.0|     1.0|I am so happy for...|    63|[i, am, so, happy...|[happy, text!, , ...|(262144,[645,1239...|(262144,[645,1239...|(262145,[645,1239...|\n",
      "|  0.0|     0.0|This sucks!  I do...|    39|[this, sucks!, , ...|[sucks!, , like, ...|(262144,[48874,18...|(262144,[48874,18...|(262145,[48874,18...|\n",
      "+-----+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1277,
     "status": "ok",
     "timestamp": 1652650301052,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "dnPMDF7er5L2",
    "outputId": "41528436-6681-45e8-ce8b-41f32bc90f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|polarity|label|features                                                                                                                     |\n",
      "+--------+-----+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|1.0     |1.0  |(262145,[645,123940,162817,183411,262144],[0.4054651081081644,0.4054651081081644,0.4054651081081644,0.4054651081081644,63.0])|\n",
      "|0.0     |0.0  |(262145,[48874,180672,208258,262144],[0.4054651081081644,0.4054651081081644,0.4054651081081644,39.0])                        |\n",
      "+--------+-----+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/31 13:00:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "22/05/31 13:00:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "22/05/31 13:00:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    }
   ],
   "source": [
    "cleaned.select(['polarity','label','features']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652650301053,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "wb8R6XO4sjt_"
   },
   "outputs": [],
   "source": [
    "# Break data down into a training set and a testing set\n",
    "#training, testing = cleaned.randomSplit([0.7, 0.3], 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "# Create a Naive Bayes model and fit training data\n",
    "#nb = NaiveBayes()\n",
    "#predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_path = \"./nb\"\n",
    "#nb.save(nb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "# Restore the saved NaiveBayes classifier\n",
    "nb2 = NaiveBayes.load(\"./nb\")\n",
    "nb2.getSmoothing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.save(\"./nb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Restored the trained predictor\n",
    "predictor2 = NaiveBayesModel.load(\"./nb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6997,
     "status": "ok",
     "timestamp": 1652650440251,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "ZRW_JNc-u7vn",
    "outputId": "d1f16c68-d715-43fc-b260-c6bc785607cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|polarity|                text|length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  1.0|     1.0|I am so happy for...|    63|[i, am, so, happy...|[happy, text!, , ...|(262144,[645,1239...|(262144,[645,1239...|(262145,[645,1239...|[-53.527404207656...|[0.57733184971333...|       0.0|\n",
      "|  0.0|     0.0|This sucks!  I do...|    39|[this, sucks!, , ...|[sucks!, , like, ...|(262144,[48874,18...|(262144,[48874,18...|(262145,[48874,18...|[-33.700769564848...|[0.87790717642727...|       0.0|\n",
      "+-----+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/31 13:00:38 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "22/05/31 13:00:38 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "22/05/31 13:00:38 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n"
     ]
    }
   ],
   "source": [
    "test_results = predictor2.transform(cleaned)\n",
    "test_results.show(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6574,
     "status": "ok",
     "timestamp": 1652650446811,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "xrn_-RE2vwFn",
    "outputId": "c4be8b40-b0a0-4dd9-f13b-9ff7dab4d3b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/31 13:00:47 WARN DAGScheduler: Broadcasting large task binary with size 23.0 MiB\n",
      "22/05/31 13:01:00 ERROR Executor: Exception in task 5.0 in stage 30.0 (TID 144)]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3942)\n",
      "\tat java.base/java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3747)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2073)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:1988)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1580)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "22/05/31 13:01:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 5.0 in stage 30.0 (TID 144),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3942)\n",
      "\tat java.base/java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3747)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2073)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:1988)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1580)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "22/05/31 13:01:00 WARN TaskSetManager: Lost task 5.0 in stage 30.0 (TID 144) (ip-192-168-50-63.us-west-2.compute.internal executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3942)\n",
      "\tat java.base/java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3747)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2073)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:1988)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1580)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n",
      "\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n",
      "\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n",
      "\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
      "\n",
      "22/05/31 13:01:00 ERROR TaskSetManager: Task 5 in stage 30.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o293.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 30.0 failed 1 times, most recent failure: Lost task 5.0 in stage 30.0 (TID 144) (ip-192-168-50-63.us-west-2.compute.internal executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3942)\n\tat java.base/java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3747)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2073)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:1988)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1580)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:304)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)\n\tat org.apache.spark.rdd.OrderedRDDFunctions.$anonfun$sortByKey$1(OrderedRDDFunctions.scala:64)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:63)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.x$3$lzycompute(BinaryClassificationMetrics.scala:189)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.x$3(BinaryClassificationMetrics.scala:178)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.confusions$lzycompute(BinaryClassificationMetrics.scala:180)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.confusions(BinaryClassificationMetrics.scala:180)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.createCurve(BinaryClassificationMetrics.scala:272)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.roc(BinaryClassificationMetrics.scala:103)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.areaUnderROC(BinaryClassificationMetrics.scala:123)\n\tat org.apache.spark.ml.evaluation.BinaryClassificationEvaluator.evaluate(BinaryClassificationEvaluator.scala:102)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:844)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3942)\n\tat java.base/java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3747)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2073)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:1988)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1580)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/gchpv8j11_55vcv6hppyq9_40000gn/T/ipykernel_4402/2435880671.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0macc_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawPredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of model at predicting Text Sentiment was: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o293.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 30.0 failed 1 times, most recent failure: Lost task 5.0 in stage 30.0 (TID 144) (ip-192-168-50-63.us-west-2.compute.internal executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3942)\n\tat java.base/java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3747)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2073)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:1988)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1580)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:304)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)\n\tat org.apache.spark.rdd.OrderedRDDFunctions.$anonfun$sortByKey$1(OrderedRDDFunctions.scala:64)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:63)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.x$3$lzycompute(BinaryClassificationMetrics.scala:189)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.x$3(BinaryClassificationMetrics.scala:178)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.confusions$lzycompute(BinaryClassificationMetrics.scala:180)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.confusions(BinaryClassificationMetrics.scala:180)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.createCurve(BinaryClassificationMetrics.scala:272)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.roc(BinaryClassificationMetrics.scala:103)\n\tat org.apache.spark.mllib.evaluation.BinaryClassificationMetrics.areaUnderROC(BinaryClassificationMetrics.scala:123)\n\tat org.apache.spark.ml.evaluation.BinaryClassificationEvaluator.evaluate(BinaryClassificationEvaluator.scala:102)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:844)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3942)\n\tat java.base/java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3747)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2073)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.readArray(ObjectInputStream.java:1988)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1580)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n\tat java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2082)\n\tat java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1586)\n\tat java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2350)\n\tat java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2244)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "acc_eval = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction')\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting Text Sentiment was: %f\" % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Thread-5\"\n"
     ]
    }
   ],
   "source": [
    "df = test_results.select(\"text\",\"label\",\"prediction\", \"probability\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"refresh progress\"\n",
      "\n",
      "Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"RemoteBlock-temp-file-clean-thread\"\n",
      "\n",
      "Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Thread-32\"\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/py4j/clientserver.py\", line 504, in send_command\n",
      "    \"Error while sending or receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "\n",
      "Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"task-result-getter-3\"\n",
      "Exception in thread \"Thread-1\" java.lang.OutOfMemoryError: Java heap space\n",
      "Exception in thread \"task-result-getter-2\" java.lang.OutOfMemoryError: Java heap space\n",
      "Exception in thread \"heartbeat-receiver-event-loop-thread\" java.lang.OutOfMemoryError: Java heap space\n",
      "Exception in thread \"Thread-15\" Exception in thread \"task-result-getter-1\" java.lang.OutOfMemoryError: Java heap space\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 2.0 in stage 54.0 (TID 281)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 8.0 in stage 54.0 (TID 287)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "Exception in thread \"shutdown-hook-0\" java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 WARN ShutdownHookManager: ShutdownHook '' failed, java.lang.OutOfMemoryError: Java heap space\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 5.0 in stage 54.0 (TID 284)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 3.0 in stage 54.0 (TID 282)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 12.0 in stage 54.0 (TID 291)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 9.0 in stage 54.0 (TID 288)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 4.0 in stage 54.0 (TID 283)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 6.0 in stage 54.0 (TID 285)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 1.0 in stage 54.0 (TID 280)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 0.0 in stage 54.0 (TID 279)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 1.0 in stage 54.0 (TID 280),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Inbox: An error happened while processing message in the inbox for LocalSchedulerBackendEndpoint\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Utils: Uncaught exception in thread driver-heartbeater\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "Exception in thread \"dispatcher-event-loop-3\" java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 14.0 in stage 54.0 (TID 293)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 15.0 in stage 54.0 (TID 294)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR Executor: Exception in task 10.0 in stage 54.0 (TID 289)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 2.0 in stage 54.0 (TID 281),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 8.0 in stage 54.0 (TID 287),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 5.0 in stage 54.0 (TID 284),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 3.0 in stage 54.0 (TID 282),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 54.0 (TID 279),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 12.0 in stage 54.0 (TID 291),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 9.0 in stage 54.0 (TID 288),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 4.0 in stage 54.0 (TID 283),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 6.0 in stage 54.0 (TID 285),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 14.0 in stage 54.0 (TID 293),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 15.0 in stage 54.0 (TID 294),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "22/05/30 23:56:32 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 10.0 in stage 54.0 (TID 289),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 59316)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/ilan/opt/anaconda3/envs/mlenv2/lib/python3.7/site-packages/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(df[\"label\"], df[\"prediction\"])\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"],\n",
    "    columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36474,
     "status": "ok",
     "timestamp": 1652650483266,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "iQgX-xzDumxu",
    "outputId": "118ad4cd-9ce2-401e-aff5-66214e99f536"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/30 19:55:25 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 0.0 in stage 10.0 (TID 31)\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$2(Task.scala:152)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:150)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:844)\n",
      "22/05/30 19:55:25 ERROR TaskContextImpl: Error in TaskCompletionListener\n",
      "java.lang.IllegalStateException: Block broadcast_18 not found\n",
      "\tat org.apache.spark.storage.BlockInfoManager.$anonfun$unlock$3(BlockInfoManager.scala:293)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:293)\n",
      "\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1254)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:289)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:289)\n",
      "\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:130)\n",
      "\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:142)\n",
      "\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:142)\n",
      "\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:197)\n",
      "\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:142)\n",
      "\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:135)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:844)\n",
      "22/05/30 19:55:25 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 3.0 in stage 10.0 (TID 34)\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$2(Task.scala:152)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:150)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:844)\n",
      "22/05/30 19:55:25 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 4.0 in stage 10.0 (TID 35)\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$2(Task.scala:152)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:150)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:844)\n",
      "22/05/30 19:55:25 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 5.0 in stage 10.0 (TID 36)\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$2(Task.scala:152)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:150)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:844)\n",
      "22/05/30 19:55:25 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 1.0 in stage 10.0 (TID 32)\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$2(Task.scala:152)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:150)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:844)\n",
      "22/05/30 19:55:25 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 6.0 in stage 10.0 (TID 37)\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.scheduler.Task.$anonfun$run$2(Task.scala:152)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1442)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:150)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:844)\n"
     ]
    }
   ],
   "source": [
    "# Store environmental variable\n",
    "from getpass import getpass\n",
    "password = getpass('Provide Password')\n",
    "\n",
    "# Configure settings for RDS\n",
    "mode = \"overwrite\"\n",
    "jdbc_url=\"jdbc:postgresql://database-1.c3f2jo4rdylg.us-west-2.rds.amazonaws.com:5432/sentiment_analysis\"\n",
    "config = {\"user\":\"postgres\", \n",
    "          \"password\": password, \n",
    "          \"driver\":\"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7025,
     "status": "ok",
     "timestamp": 1652650490287,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "jS4Czxbh2bme",
    "outputId": "3f243913-292a-4fd8-be88-17472ead0b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------------------------------------------------------------------------------------------------------------------------+--------+------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|polarity|text                                                                                                                                     |new_date|length|label|token_text                                                                                                                                                              |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |prediction|\n",
      "+--------+-----------------------------------------------------------------------------------------------------------------------------------------+--------+------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|0       |@Skunkie Sorry, I guess sarcasm is hard to show in 130 characters.                                                                       |4/7/09  |68    |0.0  |[@skunkie, sorry,, i, guess, sarcasm, is, hard, to, show, in, 130, characters.]                                                                                         |(262145,[2437,108063,116408,146050,189716,225681,245731,256883,262144],[5.259146652144797,8.51724319016628,6.4378016484864435,9.210390370726225,4.961895128676866,8.51724319016628,5.099516506552913,9.210390370726225,68.0])                                                                                                                                                                                                                                                                                                                                                                                       |0.0       |\n",
      "|0       |@honeyortar the hinge broke  it works, just doesn't open smoothly and it's pissing me off. I dunno I'll see if it can be fixed first.    |4/7/09  |133   |0.0  |[@honeyortar, the, hinge, broke, , it, works,, just, doesn't, open, smoothly, and, it's, pissing, me, off., i, dunno, i'll, see, if, it, can, be, fixed, first.]        |(262145,[8538,33197,40698,60244,112971,149980,158572,169527,191510,192278,220001,229431,249180,262144],[3.568483299788111,8.51724319016628,9.210390370726225,9.210390370726225,6.09687506151585,7.19548735018396,7.600952458292124,6.032336540378279,6.40702998981969,6.907805277732178,8.29409963885207,9.210390370726225,1.1221356436037935,133.0])                                                                                                                                                                                                                                                               |0.0       |\n",
      "|0       |@BrandzHD TAKIN A BREAK FROM THE CLUBS PLEASE DONT TELL ME WHERE U AT                                                                    |4/7/09  |70    |0.0  |[@brandzhd, takin, a, break, from, the, clubs, please, dont, tell, me, where, u, at]                                                                                    |(262145,[40912,51783,85530,87273,124348,166368,179995,199917,262144],[8.80492526261806,3.8190381382109986,5.12441405817464,4.570818758020801,6.011717253175543,4.847291745937862,7.505642278487799,9.210390370726225,70.0])                                                                                                                                                                                                                                                                                                                                                                                         |0.0       |\n",
      "|0       |@Gen_Marie  I hope we can fix you in California at least.....                                                                            |4/7/09  |61    |0.0  |[@gen_marie, , i, hope, we, can, fix, you, in, california, at, least.....]                                                                                              |(262145,[128160,164695,207112,237532,249180,252060,262144],[3.9399582076677233,9.210390370726225,8.111778082058114,7.130948829046388,1.1221356436037935,9.210390370726225,61.0])                                                                                                                                                                                                                                                                                                                                                                                                                                    |0.0       |\n",
      "|0       |Finds her mom rly annoying. I need to detox and do an H2O day. My skin is shitting.                                                      |4/7/09  |84    |0.0  |[finds, her, mom, rly, annoying., i, need, to, detox, and, do, an, h2o, day., my, skin, is, shitting.]                                                                  |(262145,[40553,83161,83668,119864,127581,141269,148123,202002,212915,220267,262144],[7.505642278487799,3.8996504841796304,7.505642278487799,8.80492526261806,9.210390370726225,5.599472458082,7.8240960096063334,5.30841770115158,9.210390370726225,9.210390370726225,84.0])                                                                                                                                                                                                                                                                                                                                        |1.0       |\n",
      "|0       |I'm off to bed... way to late... will likely be a sac a shit at work tomorrow.                                                           |4/7/09  |80    |0.0  |[i'm, off, to, bed..., way, to, late..., will, likely, be, a, sac, a, shit, at, work, tomorrow.]                                                                        |(262145,[16293,34343,51471,52671,61080,64076,70618,241121,262144],[7.8240960096063334,3.387344475243206,4.362274006127744,8.80492526261806,5.933245637734048,5.991514545858023,7.264480221670911,9.210390370726225,80.0])                                                                                                                                                                                                                                                                                                                                                                                           |0.0       |\n",
      "|0       |@kcarruthers I'm only 540 years old in pixie years.                                                                                      |4/7/09  |52    |0.0  |[@kcarruthers, i'm, only, 540, years, old, in, pixie, years.]                                                                                                           |(262145,[52677,76106,160622,182235,252934,256394,262144],[8.80492526261806,6.011717253175543,7.600952458292124,4.961895128676866,8.80492526261806,8.80492526261806,52.0])                                                                                                                                                                                                                                                                                                                                                                                                                                           |0.0       |\n",
      "|0       |body clock still up the chuffer..note never ever stay up late again -also afro is back                                                   |4/7/09  |87    |0.0  |[body, clock, still, up, the, chuffer..note, never, ever, stay, up, late, again, -also, afro, is, back]                                                                 |(262145,[21205,22171,31536,34121,68727,73249,113673,132270,162570,203802,253521,262144],[9.210390370726225,9.210390370726225,3.6119684117278497,6.76804333535702,5.212189669057026,5.472720752442856,4.514465821469669,3.429646854933895,9.210390370726225,5.1850386799910755,7.41863090149817,87.0])                                                                                                                                                                                                                                                                                                               |0.0       |\n",
      "|0       |blahhh, my throat is sore &amp; i keep coughing. i hate being sick                                                                       |4/7/09  |67    |0.0  |[blahhh,, my, throat, is, sore, &amp;, i, keep, coughing., i, hate, being, sick]                                                                                        |(262145,[7241,32890,54480,72709,130236,234437,255484,261677,262144],[9.210390370726225,5.091353195913753,3.787645425803136,4.505374849768417,6.074896154797075,9.210390370726225,6.469550346801023,4.919930929577833,67.0])                                                                                                                                                                                                                                                                                                                                                                                         |0.0       |\n",
      "|0       |3 in the morning and I can't sleep.                                                                                                      |4/7/09  |36    |0.0  |[3, in, the, morning, and, i, can't, sleep.]                                                                                                                            |(262145,[22411,131672,168590,262144],[6.165867933002802,3.9528949986984427,4.947710493684909,36.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |0.0       |\n",
      "|0       |Just wrote a 2 pg paper n 30 min, studied n now off 2 bed. Gotta wake up n 3 hours. OH JOY!  Nite all!                                   |4/7/09  |102   |0.0  |[just, wrote, a, 2, pg, paper, n, 30, min,, studied, n, now, off, 2, bed., gotta, wake, up, n, 3, hours., oh, joy!, , nite, all!]                                       |(262145,[11275,12524,18184,43237,49769,52644,58967,72510,77924,92754,93206,138651,157506,168590,217817,230168,249180,257750,262144],[5.82600010738045,7.879916415335447,3.9120730041781875,5.1586054229229195,8.29409963885207,16.211183642867713,6.6077006852818405,6.032336540378279,8.29409963885207,8.29409963885207,6.265951391559784,9.210390370726225,6.536241721299696,4.947710493684909,7.264480221670911,5.655042309236811,1.1221356436037935,6.4378016484864435,102.0])                                                                                                                                  |1.0       |\n",
      "|0       |or should i say my brain needs to optimise my neural search pathways to find my muscles again                                            |4/7/09  |94    |0.0  |[or, should, i, say, my, brain, needs, to, optimise, my, neural, search, pathways, to, find, my, muscles, again]                                                        |(262145,[42482,66669,91878,171222,197009,198060,202878,221552,249607,262144],[9.210390370726225,7.600952458292124,4.756043074472717,4.595269853884965,6.812495097927854,9.210390370726225,5.991514545858023,8.29409963885207,6.907805277732178,94.0])                                                                                                                                                                                                                                                                                                                                                               |0.0       |\n",
      "|0       |Twitter woke me up                                                                                                                       |4/7/09  |19    |0.0  |[twitter, woke, me, up]                                                                                                                                                 |(262145,[1512,75373,262144],[4.006383683649429,5.167339102891674,19.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |0.0       |\n",
      "|0       |@mrskutcher I was just thinking that today - how deprssing it all is!  Makes us appreciate life more.                                    |4/7/09  |101   |0.0  |[@mrskutcher, i, was, just, thinking, that, today, -, how, deprssing, it, all, is!, , makes, us, appreciate, life, more.]                                               |(262145,[32983,38640,64238,109156,143689,167227,172517,180288,197913,199581,219766,249180,262144],[5.328826572782787,3.1857328562624785,3.6691268255677985,4.886257714471245,8.111778082058114,7.7063129739499505,4.961895128676866,6.907805277732178,9.210390370726225,5.149947360179805,6.76804333535702,1.1221356436037935,101.0])                                                                                                                                                                                                                                                                               |1.0       |\n",
      "|0       |@Warlach Curse ye!! Have fun at it. I miss doing online PR for Paramount Pics                                                            |4/7/09  |78    |0.0  |[@warlach, curse, ye!!, have, fun, at, it., i, miss, doing, online, pr, for, paramount, pics]                                                                           |(262145,[23087,50671,79606,89820,112019,122361,143501,146984,232735,245293,262144],[4.418740617795515,6.119347917367908,6.142337435592608,8.80492526261806,9.210390370726225,8.80492526261806,4.840942518259203,9.210390370726225,3.9021226733250196,8.80492526261806,78.0])                                                                                                                                                                                                                                                                                                                                        |0.0       |\n",
      "|0       |ugh, just read on #CNN that they found the Cantu girl's body in a pond near their home. How terrible for her family                      |4/7/09  |116   |0.0  |[ugh,, just, read, on, #cnn, that, they, found, the, cantu, girl's, body, in, a, pond, near, their, home., how, terrible, for, her, family]                             |(262145,[34121,36691,53570,60179,87405,128081,143845,150278,166975,221017,239452,253698,262144],[6.76804333535702,9.210390370726225,5.176149732573829,6.812495097927854,5.1586054229229195,9.210390370726225,5.9522938327047425,6.684661726417969,8.29409963885207,5.7138828092597445,7.505642278487799,9.210390370726225,116.0])                                                                                                                                                                                                                                                                                   |0.0       |\n",
      "|0       |@markress understand that, we are all busy. I can only tweet after work.                                                                 |4/7/09  |73    |0.0  |[@markress, understand, that,, we, are, all, busy., i, can, only, tweet, after, work.]                                                                                  |(262145,[41649,124399,182660,222808,225159,234744,262144],[8.80492526261806,5.268808563056534,8.29409963885207,5.39267804476932,6.214658097172233,6.6077006852818405,73.0])                                                                                                                                                                                                                                                                                                                                                                                                                                         |0.0       |\n",
      "|0       |@samsungimaging better get your auto feature ironed out. that blast of advertisements was nothing less than industrial strength spam!    |4/7/09  |134   |0.0  |[@samsungimaging, better, get, your, auto, feature, ironed, out., that, blast, of, advertisements, was, nothing, less, than, industrial, strength, spam!]               |(262145,[4507,16337,25324,34146,38233,59096,75949,105627,116996,123874,218787,235375,245642,252722,262144],[9.210390370726225,7.264480221670911,8.80492526261806,7.7063129739499505,9.210390370726225,7.957627402230856,7.957627402230856,6.292619638641946,5.176149732573829,5.8962043660536985,9.210390370726225,4.402279340741443,9.210390370726225,3.042873879837883,134.0])                                                                                                                                                                                                                                    |0.0       |\n",
      "|0       |@GillianMe Yeah he was                                                                                                                   |4/7/09  |23    |0.0  |[@gillianme, yeah, he, was]                                                                                                                                             |(262145,[82065,107888,262144],[5.059350464827578,9.210390370726225,23.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |1.0       |\n",
      "|0       |@dougiemcfly hey saw u guys play @ pushover..didn't get 2 meet u tho cuz of th HUGE line  i was very upset lol..a msg would make up 4 it!|4/7/09  |137   |0.0  |[@dougiemcfly, hey, saw, u, guys, play, @, pushover..didn't, get, 2, meet, u, tho, cuz, of, th, huge, line, , i, was, very, upset, lol..a, msg, would, make, up, 4, it!]|(262145,[12524,45176,45190,51783,61756,89717,90225,101376,110078,112225,120504,123981,149321,150239,153524,155889,186369,194802,223018,245415,249180,252722,259059,262144],[3.9399582076677233,4.919930929577833,6.053389949576111,7.638076276421997,4.873099629893734,4.179952449333789,5.268808563056534,5.167339102891674,6.725483720938224,8.80492526261806,7.264480221670911,5.403727880955905,5.971711918561844,6.907805277732178,5.5597321294324855,6.684661726417969,5.8962043660536985,4.610232726561677,7.7063129739499505,5.107747005689428,1.1221356436037935,3.042873879837883,8.80492526261806,137.0])|0.0       |\n",
      "+--------+-----------------------------------------------------------------------------------------------------------------------------------------+--------+------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results[\"polarity\",'text','new_date',\"length\",\"label\", \"token_text\",\"features\", \"prediction\"].show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1812,
     "status": "ok",
     "timestamp": 1652650492087,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "u1xezCR7Z3aP",
    "outputId": "c40b216f-8e19-4dd2-f09d-1c9038fe11af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity , int\n",
      "id , int\n",
      "date , string\n",
      "query , string\n",
      "user , string\n",
      "text , string\n",
      "new_date , string\n",
      "length , int\n",
      "label , double\n",
      "token_text , array<string>\n",
      "stop_tokens , array<string>\n",
      "hash_token , vector\n",
      "idf_token , vector\n",
      "features , vector\n",
      "rawPrediction , vector\n",
      "probability , vector\n",
      "prediction , double\n"
     ]
    }
   ],
   "source": [
    "for col in test_results.dtypes:\n",
    "    print(col[0]+\" , \"+col[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6255,
     "status": "ok",
     "timestamp": 1652650498338,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "gSqAylgwfq7-",
    "outputId": "03dade5e-a32b-4ae7-bae7-345e4b748aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------------------------+--------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------+--------+------+-----+-----------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------+-------------------------------------------+----------+\n",
      "|polarity|id        |date                        |query   |user          |text                                                                                                                                     |new_date|length|label|token_text                                                                                                                               |stop_tokens                                                                                                       |hash_token                                                                                                                                                                                                                                                        |idf_token                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |rawPrediction                            |probability                                |prediction|\n",
      "+--------+----------+----------------------------+--------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------+--------+------+-----+-----------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------+-------------------------------------------+----------+\n",
      "|0       |1468159766|Tue Apr 07 00:02:28 PDT 2009|NO_QUERY|amcpodcast    |@Skunkie Sorry, I guess sarcasm is hard to show in 130 characters.                                                                       |4/7/09  |68    |0.0  |@skunkie,sorry,,i,guess,sarcasm,is,hard,to,show,in,130,characters.                                                                       |@skunkie,sorry,,guess,sarcasm,hard,show,130,characters.                                                           |(262144,[2437,108063,116408,146050,189716,225681,245731,256883],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                |(262144,[2437,108063,116408,146050,189716,225681,245731,256883],[5.259146652144797,8.51724319016628,6.4378016484864435,9.210390370726225,4.961895128676866,8.51724319016628,5.099516506552913,9.210390370726225])                                                                                                                                                                                                                                                                                                                                                                                      |(262145,[2437,108063,116408,146050,189716,225681,245731,256883,262144],[5.259146652144797,8.51724319016628,6.4378016484864435,9.210390370726225,4.961895128676866,8.51724319016628,5.099516506552913,9.210390370726225,68.0])                                                                                                                                                                                                                                                                                                                                                                                       |[-717.1927565700546,-728.1113618341803]  |[0.9999818823395866,1.8117660413285056E-5] |0.0       |\n",
      "|0       |1468160655|Tue Apr 07 00:02:47 PDT 2009|NO_QUERY|hamb0         |@honeyortar the hinge broke  it works, just doesn't open smoothly and it's pissing me off. I dunno I'll see if it can be fixed first.    |4/7/09  |133   |0.0  |@honeyortar,the,hinge,broke,,it,works,,just,doesn't,open,smoothly,and,it's,pissing,me,off.,i,dunno,i'll,see,if,it,can,be,fixed,first.    |@honeyortar,hinge,broke,,works,,open,smoothly,pissing,off.,dunno,see,fixed,first.                                 |(262144,[8538,33197,40698,60244,112971,149980,158572,169527,191510,192278,220001,229431,249180],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                            |(262144,[8538,33197,40698,60244,112971,149980,158572,169527,191510,192278,220001,229431,249180],[3.568483299788111,8.51724319016628,9.210390370726225,9.210390370726225,6.09687506151585,7.19548735018396,7.600952458292124,6.032336540378279,6.40702998981969,6.907805277732178,8.29409963885207,9.210390370726225,1.1221356436037935])                                                                                                                                                                                                                                                               |(262145,[8538,33197,40698,60244,112971,149980,158572,169527,191510,192278,220001,229431,249180,262144],[3.568483299788111,8.51724319016628,9.210390370726225,9.210390370726225,6.09687506151585,7.19548735018396,7.600952458292124,6.032336540378279,6.40702998981969,6.907805277732178,8.29409963885207,9.210390370726225,1.1221356436037935,133.0])                                                                                                                                                                                                                                                               |[-1129.9684510864552,-1175.2724614644026]|[1.0,2.1121185205064296E-20]               |0.0       |\n",
      "|0       |1468161997|Tue Apr 07 00:03:12 PDT 2009|NO_QUERY|mixgrindhnic  |@BrandzHD TAKIN A BREAK FROM THE CLUBS PLEASE DONT TELL ME WHERE U AT                                                                    |4/7/09  |70    |0.0  |@brandzhd,takin,a,break,from,the,clubs,please,dont,tell,me,where,u,at                                                                    |@brandzhd,takin,break,clubs,please,dont,tell,u                                                                    |(262144,[40912,51783,85530,87273,124348,166368,179995,199917],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                  |(262144,[40912,51783,85530,87273,124348,166368,179995,199917],[8.80492526261806,3.8190381382109986,5.12441405817464,4.570818758020801,6.011717253175543,4.847291745937862,7.505642278487799,9.210390370726225])                                                                                                                                                                                                                                                                                                                                                                                        |(262145,[40912,51783,85530,87273,124348,166368,179995,199917,262144],[8.80492526261806,3.8190381382109986,5.12441405817464,4.570818758020801,6.011717253175543,4.847291745937862,7.505642278487799,9.210390370726225,70.0])                                                                                                                                                                                                                                                                                                                                                                                         |[-590.8295296996431,-601.6517021803124]  |[0.9999800482247304,1.9951775269578206E-5] |0.0       |\n",
      "|0       |1468163061|Tue Apr 07 00:03:34 PDT 2009|NO_QUERY|fantatango    |@Gen_Marie  I hope we can fix you in California at least.....                                                                            |4/7/09  |61    |0.0  |@gen_marie,,i,hope,we,can,fix,you,in,california,at,least.....                                                                            |@gen_marie,,hope,fix,california,least.....                                                                        |(262144,[128160,164695,207112,237532,249180,252060],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                    |(262144,[128160,164695,207112,237532,249180,252060],[3.9399582076677233,9.210390370726225,8.111778082058114,7.130948829046388,1.1221356436037935,9.210390370726225])                                                                                                                                                                                                                                                                                                                                                                                                                                   |(262145,[128160,164695,207112,237532,249180,252060,262144],[3.9399582076677233,9.210390370726225,8.111778082058114,7.130948829046388,1.1221356436037935,9.210390370726225,61.0])                                                                                                                                                                                                                                                                                                                                                                                                                                    |[-506.6067988972389,-507.1486454204833]  |[0.6322418614578834,0.36775813854211664]   |0.0       |\n",
      "|0       |1468167146|Tue Apr 07 00:04:55 PDT 2009|NO_QUERY|Li_a          |Finds her mom rly annoying. I need to detox and do an H2O day. My skin is shitting.                                                      |4/7/09  |84    |0.0  |finds,her,mom,rly,annoying.,i,need,to,detox,and,do,an,h2o,day.,my,skin,is,shitting.                                                      |finds,mom,rly,annoying.,need,detox,h2o,day.,skin,shitting.                                                        |(262144,[40553,83161,83668,119864,127581,141269,148123,202002,212915,220267],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                           |(262144,[40553,83161,83668,119864,127581,141269,148123,202002,212915,220267],[7.505642278487799,3.8996504841796304,7.505642278487799,8.80492526261806,9.210390370726225,5.599472458082,7.8240960096063334,5.30841770115158,9.210390370726225,9.210390370726225])                                                                                                                                                                                                                                                                                                                                       |(262145,[40553,83161,83668,119864,127581,141269,148123,202002,212915,220267,262144],[7.505642278487799,3.8996504841796304,7.505642278487799,8.80492526261806,9.210390370726225,5.599472458082,7.8240960096063334,5.30841770115158,9.210390370726225,9.210390370726225,84.0])                                                                                                                                                                                                                                                                                                                                        |[-944.4377906036077,-939.3701958318964]  |[0.0062581380513934805,0.9937418619486065] |1.0       |\n",
      "|0       |1468167349|Tue Apr 07 00:04:59 PDT 2009|NO_QUERY|_LLcoolV_     |I'm off to bed... way to late... will likely be a sac a shit at work tomorrow.                                                           |4/7/09  |80    |0.0  |i'm,off,to,bed...,way,to,late...,will,likely,be,a,sac,a,shit,at,work,tomorrow.                                                           |bed...,way,late...,likely,sac,shit,work,tomorrow.                                                                 |(262144,[16293,34343,51471,52671,61080,64076,70618,241121],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                     |(262144,[16293,34343,51471,52671,61080,64076,70618,241121],[7.8240960096063334,3.387344475243206,4.362274006127744,8.80492526261806,5.933245637734048,5.991514545858023,7.264480221670911,9.210390370726225])                                                                                                                                                                                                                                                                                                                                                                                          |(262145,[16293,34343,51471,52671,61080,64076,70618,241121,262144],[7.8240960096063334,3.387344475243206,4.362274006127744,8.80492526261806,5.933245637734048,5.991514545858023,7.264480221670911,9.210390370726225,80.0])                                                                                                                                                                                                                                                                                                                                                                                           |[-643.6430724506251,-658.2149626793096]  |[0.9999995306376184,4.6936238167099094E-7] |0.0       |\n",
      "|0       |1468167571|Tue Apr 07 00:05:02 PDT 2009|NO_QUERY|SilkCharm     |@kcarruthers I'm only 540 years old in pixie years.                                                                                      |4/7/09  |52    |0.0  |@kcarruthers,i'm,only,540,years,old,in,pixie,years.                                                                                      |@kcarruthers,540,years,old,pixie,years.                                                                           |(262144,[52677,76106,160622,182235,252934,256394],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                      |(262144,[52677,76106,160622,182235,252934,256394],[8.80492526261806,6.011717253175543,7.600952458292124,4.961895128676866,8.80492526261806,8.80492526261806])                                                                                                                                                                                                                                                                                                                                                                                                                                          |(262145,[52677,76106,160622,182235,252934,256394,262144],[8.80492526261806,6.011717253175543,7.600952458292124,4.961895128676866,8.80492526261806,8.80492526261806,52.0])                                                                                                                                                                                                                                                                                                                                                                                                                                           |[-566.5699319664168,-590.9994459030689]  |[0.9999999999754305,2.4569532995537904E-11]|0.0       |\n",
      "|0       |1468167936|Tue Apr 07 00:05:09 PDT 2009|NO_QUERY|dontlookaway  |body clock still up the chuffer..note never ever stay up late again -also afro is back                                                   |4/7/09  |87    |0.0  |body,clock,still,up,the,chuffer..note,never,ever,stay,up,late,again,-also,afro,is,back                                                   |body,clock,still,chuffer..note,never,ever,stay,late,-also,afro,back                                               |(262144,[21205,22171,31536,34121,68727,73249,113673,132270,162570,203802,253521],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                   |(262144,[21205,22171,31536,34121,68727,73249,113673,132270,162570,203802,253521],[9.210390370726225,9.210390370726225,3.6119684117278497,6.76804333535702,5.212189669057026,5.472720752442856,4.514465821469669,3.429646854933895,9.210390370726225,5.1850386799910755,7.41863090149817])                                                                                                                                                                                                                                                                                                              |(262145,[21205,22171,31536,34121,68727,73249,113673,132270,162570,203802,253521,262144],[9.210390370726225,9.210390370726225,3.6119684117278497,6.76804333535702,5.212189669057026,5.472720752442856,4.514465821469669,3.429646854933895,9.210390370726225,5.1850386799910755,7.41863090149817,87.0])                                                                                                                                                                                                                                                                                                               |[-824.0517342714749,-837.3243053509532]  |[0.9999982789445137,1.721055486277915E-6]  |0.0       |\n",
      "|0       |1468168741|Tue Apr 07 00:05:25 PDT 2009|NO_QUERY|erriiinnn     |blahhh, my throat is sore &amp; i keep coughing. i hate being sick                                                                       |4/7/09  |67    |0.0  |blahhh,,my,throat,is,sore,&amp;,i,keep,coughing.,i,hate,being,sick                                                                       |blahhh,,throat,sore,&amp;,keep,coughing.,hate,sick                                                                |(262144,[7241,32890,54480,72709,130236,234437,255484,261677],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                   |(262144,[7241,32890,54480,72709,130236,234437,255484,261677],[9.210390370726225,5.091353195913753,3.787645425803136,4.505374849768417,6.074896154797075,9.210390370726225,6.469550346801023,4.919930929577833])                                                                                                                                                                                                                                                                                                                                                                                        |(262145,[7241,32890,54480,72709,130236,234437,255484,261677,262144],[9.210390370726225,5.091353195913753,3.787645425803136,4.505374849768417,6.074896154797075,9.210390370726225,6.469550346801023,4.919930929577833,67.0])                                                                                                                                                                                                                                                                                                                                                                                         |[-572.2521813706973,-608.8715753452136]  |[0.9999999999999998,1.2485308166696957E-16]|0.0       |\n",
      "|0       |1468169708|Tue Apr 07 00:05:40 PDT 2009|NO_QUERY|oleroleroler  |3 in the morning and I can't sleep.                                                                                                      |4/7/09  |36    |0.0  |3,in,the,morning,and,i,can't,sleep.                                                                                                      |3,morning,sleep.                                                                                                  |(262144,[22411,131672,168590],[1.0,1.0,1.0])                                                                                                                                                                                                                      |(262144,[22411,131672,168590],[6.165867933002802,3.9528949986984427,4.947710493684909])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |(262145,[22411,131672,168590,262144],[6.165867933002802,3.9528949986984427,4.947710493684909,36.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |[-159.3658793626904,-160.58533830085125] |[0.7719683185773129,0.22803168142268726]   |0.0       |\n",
      "|0       |1468169853|Tue Apr 07 00:05:44 PDT 2009|NO_QUERY|KIKILICOUS    |Just wrote a 2 pg paper n 30 min, studied n now off 2 bed. Gotta wake up n 3 hours. OH JOY!  Nite all!                                   |4/7/09  |102   |0.0  |just,wrote,a,2,pg,paper,n,30,min,,studied,n,now,off,2,bed.,gotta,wake,up,n,3,hours.,oh,joy!,,nite,all!                                   |wrote,2,pg,paper,n,30,min,,studied,n,2,bed.,gotta,wake,n,3,hours.,oh,joy!,,nite,all!                              |(262144,[11275,12524,18184,43237,49769,52644,58967,72510,77924,92754,93206,138651,157506,168590,217817,230168,249180,257750],[1.0,2.0,1.0,1.0,1.0,3.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                           |(262144,[11275,12524,18184,43237,49769,52644,58967,72510,77924,92754,93206,138651,157506,168590,217817,230168,249180,257750],[5.82600010738045,7.879916415335447,3.9120730041781875,5.1586054229229195,8.29409963885207,16.211183642867713,6.6077006852818405,6.032336540378279,8.29409963885207,8.29409963885207,6.265951391559784,9.210390370726225,6.536241721299696,4.947710493684909,7.264480221670911,5.655042309236811,1.1221356436037935,6.4378016484864435])                                                                                                                                  |(262145,[11275,12524,18184,43237,49769,52644,58967,72510,77924,92754,93206,138651,157506,168590,217817,230168,249180,257750,262144],[5.82600010738045,7.879916415335447,3.9120730041781875,5.1586054229229195,8.29409963885207,16.211183642867713,6.6077006852818405,6.032336540378279,8.29409963885207,8.29409963885207,6.265951391559784,9.210390370726225,6.536241721299696,4.947710493684909,7.264480221670911,5.655042309236811,1.1221356436037935,6.4378016484864435,102.0])                                                                                                                                  |[-1350.1630438530453,-1323.6046306773587]|[2.9229925583727287E-12,0.999999999997077] |1.0       |\n",
      "|0       |1468170137|Tue Apr 07 00:05:48 PDT 2009|NO_QUERY|phillmidwinter|or should i say my brain needs to optimise my neural search pathways to find my muscles again                                            |4/7/09  |94    |0.0  |or,should,i,say,my,brain,needs,to,optimise,my,neural,search,pathways,to,find,my,muscles,again                                            |say,brain,needs,optimise,neural,search,pathways,find,muscles                                                      |(262144,[42482,66669,91878,171222,197009,198060,202878,221552,249607],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                      |(262144,[42482,66669,91878,171222,197009,198060,202878,221552,249607],[9.210390370726225,7.600952458292124,4.756043074472717,4.595269853884965,6.812495097927854,9.210390370726225,5.991514545858023,8.29409963885207,6.907805277732178])                                                                                                                                                                                                                                                                                                                                                              |(262145,[42482,66669,91878,171222,197009,198060,202878,221552,249607,262144],[9.210390370726225,7.600952458292124,4.756043074472717,4.595269853884965,6.812495097927854,9.210390370726225,5.991514545858023,8.29409963885207,6.907805277732178,94.0])                                                                                                                                                                                                                                                                                                                                                               |[-772.1403388153936,-811.1139354691165]  |[1.0,1.185719694277728E-17]                |0.0       |\n",
      "|0       |1468170829|Tue Apr 07 00:06:01 PDT 2009|NO_QUERY|WooopJess     |Twitter woke me up                                                                                                                       |4/7/09  |19    |0.0  |twitter,woke,me,up                                                                                                                       |twitter,woke                                                                                                      |(262144,[1512,75373],[1.0,1.0])                                                                                                                                                                                                                                   |(262144,[1512,75373],[4.006383683649429,5.167339102891674])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |(262145,[1512,75373,262144],[4.006383683649429,5.167339102891674,19.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |[-91.75939918040399,-91.95966963711908]  |[0.5499009389290205,0.4500990610709795]    |0.0       |\n",
      "|0       |1468171865|Tue Apr 07 00:06:24 PDT 2009|NO_QUERY|msJLoh        |@mrskutcher I was just thinking that today - how deprssing it all is!  Makes us appreciate life more.                                    |4/7/09  |101   |0.0  |@mrskutcher,i,was,just,thinking,that,today,-,how,deprssing,it,all,is!,,makes,us,appreciate,life,more.                                    |@mrskutcher,thinking,today,-,deprssing,is!,,makes,us,appreciate,life,more.                                        |(262144,[32983,38640,64238,109156,143689,167227,172517,180288,197913,199581,219766,249180],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                     |(262144,[32983,38640,64238,109156,143689,167227,172517,180288,197913,199581,219766,249180],[5.328826572782787,3.1857328562624785,3.6691268255677985,4.886257714471245,8.111778082058114,7.7063129739499505,4.961895128676866,6.907805277732178,9.210390370726225,5.149947360179805,6.76804333535702,1.1221356436037935])                                                                                                                                                                                                                                                                               |(262145,[32983,38640,64238,109156,143689,167227,172517,180288,197913,199581,219766,249180,262144],[5.328826572782787,3.1857328562624785,3.6691268255677985,4.886257714471245,8.111778082058114,7.7063129739499505,4.961895128676866,6.907805277732178,9.210390370726225,5.149947360179805,6.76804333535702,1.1221356436037935,101.0])                                                                                                                                                                                                                                                                               |[-787.0454767590323,-741.8285857451541]  |[2.3043781247263284E-20,1.0]               |1.0       |\n",
      "|0       |1468173029|Tue Apr 07 00:06:44 PDT 2009|NO_QUERY|ScottRhodie   |@Warlach Curse ye!! Have fun at it. I miss doing online PR for Paramount Pics                                                            |4/7/09  |78    |0.0  |@warlach,curse,ye!!,have,fun,at,it.,i,miss,doing,online,pr,for,paramount,pics                                                            |@warlach,curse,ye!!,fun,it.,miss,online,pr,paramount,pics                                                         |(262144,[23087,50671,79606,89820,112019,122361,143501,146984,232735,245293],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                            |(262144,[23087,50671,79606,89820,112019,122361,143501,146984,232735,245293],[4.418740617795515,6.119347917367908,6.142337435592608,8.80492526261806,9.210390370726225,8.80492526261806,4.840942518259203,9.210390370726225,3.9021226733250196,8.80492526261806])                                                                                                                                                                                                                                                                                                                                       |(262145,[23087,50671,79606,89820,112019,122361,143501,146984,232735,245293,262144],[4.418740617795515,6.119347917367908,6.142337435592608,8.80492526261806,9.210390370726225,8.80492526261806,4.840942518259203,9.210390370726225,3.9021226733250196,8.80492526261806,78.0])                                                                                                                                                                                                                                                                                                                                        |[-872.2597764005823,-890.637291108701]   |[0.9999999895588877,1.0441112294379541E-8] |0.0       |\n",
      "|0       |1468173373|Tue Apr 07 00:06:51 PDT 2009|NO_QUERY|Elligirl      |ugh, just read on #CNN that they found the Cantu girl's body in a pond near their home. How terrible for her family                      |4/7/09  |116   |0.0  |ugh,,just,read,on,#cnn,that,they,found,the,cantu,girl's,body,in,a,pond,near,their,home.,how,terrible,for,her,family                      |ugh,,read,#cnn,found,cantu,girl's,body,pond,near,home.,terrible,family                                            |(262144,[34121,36691,53570,60179,87405,128081,143845,150278,166975,221017,239452,253698],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                       |(262144,[34121,36691,53570,60179,87405,128081,143845,150278,166975,221017,239452,253698],[6.76804333535702,9.210390370726225,5.176149732573829,6.812495097927854,5.1586054229229195,9.210390370726225,5.9522938327047425,6.684661726417969,8.29409963885207,5.7138828092597445,7.505642278487799,9.210390370726225])                                                                                                                                                                                                                                                                                   |(262145,[34121,36691,53570,60179,87405,128081,143845,150278,166975,221017,239452,253698,262144],[6.76804333535702,9.210390370726225,5.176149732573829,6.812495097927854,5.1586054229229195,9.210390370726225,5.9522938327047425,6.684661726417969,8.29409963885207,5.7138828092597445,7.505642278487799,9.210390370726225,116.0])                                                                                                                                                                                                                                                                                   |[-1040.5896861201568,-1099.2896173893425]|[1.0,3.2132444174692346E-26]               |0.0       |\n",
      "|0       |1468173987|Tue Apr 07 00:07:03 PDT 2009|NO_QUERY|RommelCali    |@markress understand that, we are all busy. I can only tweet after work.                                                                 |4/7/09  |73    |0.0  |@markress,understand,that,,we,are,all,busy.,i,can,only,tweet,after,work.                                                                 |@markress,understand,that,,busy.,tweet,work.                                                                      |(262144,[41649,124399,182660,222808,225159,234744],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                                                                                                     |(262144,[41649,124399,182660,222808,225159,234744],[8.80492526261806,5.268808563056534,8.29409963885207,5.39267804476932,6.214658097172233,6.6077006852818405])                                                                                                                                                                                                                                                                                                                                                                                                                                        |(262145,[41649,124399,182660,222808,225159,234744,262144],[8.80492526261806,5.268808563056534,8.29409963885207,5.39267804476932,6.214658097172233,6.6077006852818405,73.0])                                                                                                                                                                                                                                                                                                                                                                                                                                         |[-490.24553412381744,-495.4933409121612] |[0.9947684728625239,0.005231527137476181]  |0.0       |\n",
      "|0       |1468174134|Tue Apr 07 00:07:05 PDT 2009|NO_QUERY|ddgriffith    |@samsungimaging better get your auto feature ironed out. that blast of advertisements was nothing less than industrial strength spam!    |4/7/09  |134   |0.0  |@samsungimaging,better,get,your,auto,feature,ironed,out.,that,blast,of,advertisements,was,nothing,less,than,industrial,strength,spam!    |@samsungimaging,better,get,auto,feature,ironed,out.,blast,advertisements,nothing,less,industrial,strength,spam!   |(262144,[4507,16337,25324,34146,38233,59096,75949,105627,116996,123874,218787,235375,245642,252722],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                                                                    |(262144,[4507,16337,25324,34146,38233,59096,75949,105627,116996,123874,218787,235375,245642,252722],[9.210390370726225,7.264480221670911,8.80492526261806,7.7063129739499505,9.210390370726225,7.957627402230856,7.957627402230856,6.292619638641946,5.176149732573829,5.8962043660536985,9.210390370726225,4.402279340741443,9.210390370726225,3.042873879837883])                                                                                                                                                                                                                                    |(262145,[4507,16337,25324,34146,38233,59096,75949,105627,116996,123874,218787,235375,245642,252722,262144],[9.210390370726225,7.264480221670911,8.80492526261806,7.7063129739499505,9.210390370726225,7.957627402230856,7.957627402230856,6.292619638641946,5.176149732573829,5.8962043660536985,9.210390370726225,4.402279340741443,9.210390370726225,3.042873879837883,134.0])                                                                                                                                                                                                                                    |[-1307.7212108349124,-1319.6919804663055]|[0.9999936735794636,6.326420536391266E-6]  |0.0       |\n",
      "|0       |1468174290|Tue Apr 07 00:07:08 PDT 2009|NO_QUERY|emmaketurah   |@GillianMe Yeah he was                                                                                                                   |4/7/09  |23    |0.0  |@gillianme,yeah,he,was                                                                                                                   |@gillianme,yeah                                                                                                   |(262144,[82065,107888],[1.0,1.0])                                                                                                                                                                                                                                 |(262144,[82065,107888],[5.059350464827578,9.210390370726225])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |(262145,[82065,107888,262144],[5.059350464827578,9.210390370726225,23.0])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |[-191.57021684834012,-190.726737667324]  |[0.30080253461716777,0.6991974653828323]   |1.0       |\n",
      "|0       |1468174531|Tue Apr 07 00:07:12 PDT 2009|NO_QUERY|mcsteph94     |@dougiemcfly hey saw u guys play @ pushover..didn't get 2 meet u tho cuz of th HUGE line  i was very upset lol..a msg would make up 4 it!|4/7/09  |137   |0.0  |@dougiemcfly,hey,saw,u,guys,play,@,pushover..didn't,get,2,meet,u,tho,cuz,of,th,huge,line,,i,was,very,upset,lol..a,msg,would,make,up,4,it!|@dougiemcfly,hey,saw,u,guys,play,@,pushover..didn't,get,2,meet,u,tho,cuz,th,huge,line,,upset,lol..a,msg,make,4,it!|(262144,[12524,45176,45190,51783,61756,89717,90225,101376,110078,112225,120504,123981,149321,150239,153524,155889,186369,194802,223018,245415,249180,252722,259059],[1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(262144,[12524,45176,45190,51783,61756,89717,90225,101376,110078,112225,120504,123981,149321,150239,153524,155889,186369,194802,223018,245415,249180,252722,259059],[3.9399582076677233,4.919930929577833,6.053389949576111,7.638076276421997,4.873099629893734,4.179952449333789,5.268808563056534,5.167339102891674,6.725483720938224,8.80492526261806,7.264480221670911,5.403727880955905,5.971711918561844,6.907805277732178,5.5597321294324855,6.684661726417969,5.8962043660536985,4.610232726561677,7.7063129739499505,5.107747005689428,1.1221356436037935,3.042873879837883,8.80492526261806])|(262145,[12524,45176,45190,51783,61756,89717,90225,101376,110078,112225,120504,123981,149321,150239,153524,155889,186369,194802,223018,245415,249180,252722,259059,262144],[3.9399582076677233,4.919930929577833,6.053389949576111,7.638076276421997,4.873099629893734,4.179952449333789,5.268808563056534,5.167339102891674,6.725483720938224,8.80492526261806,7.264480221670911,5.403727880955905,5.971711918561844,6.907805277732178,5.5597321294324855,6.684661726417969,5.8962043660536985,4.610232726561677,7.7063129739499505,5.107747005689428,1.1221356436037935,3.042873879837883,8.80492526261806,137.0])|[-1349.3811846666788,-1404.327433725202] |[1.0,1.3713465952485472E-24]               |0.0       |\n",
      "+--------+----------+----------------------------+--------+--------------+-----------------------------------------------------------------------------------------------------------------------------------------+--------+------+-----+-----------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------+-------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat_ws\n",
    "test_results2 = test_results.withColumn(\"token_text\", concat_ws(\",\",col(\"token_text\")))\n",
    "test_results3 = test_results2.withColumn(\"stop_tokens\", concat_ws(\",\",col(\"stop_tokens\")))\n",
    "test_results3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 13110,
     "status": "ok",
     "timestamp": 1652650511434,
     "user": {
      "displayName": "Ilan",
      "userId": "09321244954808786476"
     },
     "user_tz": 420
    },
    "id": "aAL7ecfEw3Id"
   },
   "outputs": [],
   "source": [
    "# Write DataFrame to active_user table in RDS\n",
    "test_results['polarity','text','new_date',\"length\",\"label\", \"token_text\", \"prediction\"].write.jdbc(url=jdbc_url, table='test_results', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from flask import session\n",
    "\n",
    "\n",
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "with open('../myconfig.json','r') as fh:\n",
    "    config = json.load(fh)\n",
    "os.environ[\"BEARER_TOKEN\"] = config[\"BEARER_TOKEN\"]\n",
    "\n",
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2FilteredStreamPython\"\n",
    "    return r\n",
    "\n",
    "def create_rules(hashtag_data):\n",
    "        new_rules = '{\"rules\" : ['\n",
    "        counter = 0\n",
    "        for hashtag in hashtag_data['tw_trends']:\n",
    "            counter = counter + 1\n",
    "            if counter == 1:\n",
    "                new_rules = new_rules + '{\"value\": \"' + hashtag['hashtag'] + ' -is:retweet lang:en -has:links -has:media\", \"tag\": \"' + hashtag['hashtag'] + '\"}'\n",
    "            else:\n",
    "                new_rules = new_rules + ',{\"value\": \"' + hashtag['hashtag'] + ' -is:retweet lang:en -has:links -has:media\", \"tag\": \"' + hashtag['hashtag'] + '\"}'\n",
    "        new_rules = new_rules + ']}'        \n",
    "        print(new_rules)\n",
    "        return(new_rules)\n",
    "\n",
    "def get_rules():\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\", auth=bearer_oauth\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print('get_rules() response:')    \n",
    "    print(json.dumps(response.json()))\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def delete_all_rules(rules):\n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        auth=bearer_oauth,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    print('delete_all_rules(rules) response:')    \n",
    "    \n",
    "    (json.dumps(response.json()))\n",
    "\n",
    "\n",
    "def set_rules(rules):\n",
    "    # You can adjust the rules if needed \n",
    "    # if the passed in rules is null, then \n",
    "    if rules is None:\n",
    "        sample_rules = [\n",
    "            {\"value\": \"dog has:images\", \"tag\": \"dog pictures\"},\n",
    "            {\"value\": \"cat has:images -grumpy\", \"tag\": \"cat pictures\"},\n",
    "        ]\n",
    "    else:\n",
    "        print('assigning specified rules')\n",
    "        sample_rules = rules\n",
    "    payload = {\"add\": sample_rules}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        auth=bearer_oauth,\n",
    "        json=payload,\n",
    "    )\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Cannot add rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print('set_rules(delete) response:')      \n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "\n",
    "def get_stream(countOfTweets):\n",
    "    countOfTweets = int(countOfTweets)\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream\", auth=bearer_oauth, stream=True,\n",
    "    )\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    all_responses = []\n",
    "    count = 0\n",
    "    for response_line in response.iter_lines():\n",
    "        if count >= countOfTweets:\n",
    "            break;\n",
    "\n",
    "        if response_line:\n",
    "            # get the current tweet json\n",
    "            json_response = json.loads(response_line)    \n",
    " \n",
    "            # Keep count of the processed tweets\n",
    "            count = count + 1 \n",
    "\n",
    "            # initialize a dict to hold the current tweet\n",
    "            tweet = {}\n",
    "\n",
    "            # extract the data from the tweet and store it in our variable\n",
    "            tweet['count'] = count\n",
    "            tweet['id'] = json_response[\"data\"][\"id\"]\n",
    "            tweet[\"text\"] = json_response[\"data\"][\"text\"]\n",
    "            tweet[\"tag\"] = json_response[\"matching_rules\"][0][\"tag\"]\n",
    "\n",
    "            # Update Session with current tweet.\n",
    "            #session['current_tweet'] = tweet \n",
    "\n",
    "            # add the tweet to our response list\n",
    "            all_responses.append(tweet)\n",
    "\n",
    "            #print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "            print('tweets streamed: ' + str(count))\n",
    "    #take the streamed responses, put it into a dataframe and print the dataframe        \n",
    "    #df = pd.DataFrame(all_responses)\n",
    "    #print(df)\n",
    "\n",
    "    #return the streamed responses         \n",
    "    return(all_responses)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "def main():\n",
    "    rules = get_rules()\n",
    "    delete = delete_all_rules(rules)\n",
    "    set = set_rules(delete)\n",
    "    get_stream(set) \n",
    "    \n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "\n",
    "# Create the spark session\n",
    "spark = SparkSession.builder.appName(\"Twitter_Sentiment_NLP\").getOrCreate()\n",
    "\n",
    "#Pre-Load the classifier and the model\n",
    "# Load the saved NaiveBayes Classifier\n",
    "nb = NaiveBayes.load(\"../static/resources/nb\")\n",
    "\n",
    "#Restored the trained predictor (Trained on 1 mil tweets)\n",
    "predictor = NaiveBayesModel.load(\"../static/resources/nb_model\")\n",
    "\n",
    "def eval_text_single(text, polarity = 1.0):\n",
    "    list = [\n",
    "    {\"polarity\": polarity, \"text\" : text}\n",
    "    ]\n",
    "\n",
    "    # The pipeline doesn't work as well when it it just one record in the list, so creating a fake list and adding the request to it.\n",
    "    text_list = [{\"text\": \"I am so happy for this text!  I can now have everything I want.\", \"polarity\": 1.0},\n",
    "             {\"text\": \"This sucks!  I don't like this anymore.\", \"polarity\": 0.0},\n",
    "             {\"text\" : \"This is a bad text.\", \"polarity\" : 0.0},\n",
    "             {\"text\": \"I love you.\", \"polarity\": 0.0},\n",
    "             {\"text\": \"Wow!  I can't believe how great this is.\", \"polarity\": 0.0},\n",
    "            ]\n",
    "    \n",
    "    # Add to the fake list\n",
    "    text_list.append({\"text\" : text, \"polarity\" : polarity})\n",
    "    \n",
    "    tweet_df = spark.createDataFrame(text_list)\n",
    "\n",
    "    # Create a length column to be used as a future feature\n",
    "    data_df = tweet_df.withColumn('length', length(tweet_df['text']))\n",
    "\n",
    "    # Create all the features to the data set\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "    stopRemove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "    hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
    "    idf = IDF(inputCol='hash_token', outputCol='idf_token')\n",
    "\n",
    "    # Create feature vectors\n",
    "    clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')\n",
    "\n",
    "    # Create and run a data processing Pipeline\n",
    "    data_prep_pipeline = Pipeline(stages=[tokenizer, stopRemove, hashingTF, idf, clean_up])\n",
    "\n",
    "    # Fit and transform the pipeline\n",
    "    cleaner = data_prep_pipeline.fit(data_df)\n",
    "    cleaned = cleaner.transform(data_df)\n",
    "\n",
    "    # Load the saved NaiveBayes Classifier\n",
    "    #nb = NaiveBayes.load(\"static/resources/nb\")\n",
    "\n",
    "    #Restored the trained predictor (Trained on 1 mil tweets)\n",
    "    #predictor = NaiveBayesModel.load(\"static/resources/nb_model\")\n",
    "\n",
    "    #Predict the sentiment of the text using the restored predictor\n",
    "    test_results = predictor.transform(cleaned)\n",
    "\n",
    "    df = test_results.select(\"text\",\"prediction\", \"probability\").toPandas()\n",
    "\n",
    "    positives = [prob[1] for prob in df['probability']]\n",
    "    df['probability'] = positives\n",
    "    \n",
    "    #Prepare the results, show the first row \n",
    "    result = {}\n",
    "    result[\"text\"] = df[\"text\"][5]\n",
    "    result[\"prediction\"] = df[\"prediction\"][5]\n",
    "    result[\"probability\"] = df[\"probability\"][5]\n",
    "\n",
    "    if result[\"prediction\"] == 1:\n",
    "        result[\"prediction\"] = \"Positive\"\n",
    "    else: \n",
    "        result[\"prediction\"] = \"Negative\"\n",
    "\n",
    "    return(result)\n",
    "\n",
    "def eval_text_list(text_list):\n",
    "\n",
    "    tweet_df = spark.createDataFrame(text_list)\n",
    "\n",
    "    # Create a length column to be used as a future feature\n",
    "    data_df = tweet_df.withColumn('length', length(tweet_df['text']))\n",
    "\n",
    "    # Create all the features to the data set\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "    stopRemove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "    hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
    "    idf = IDF(inputCol='hash_token', outputCol='idf_token')\n",
    "\n",
    "    # Create feature vectors\n",
    "    clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')\n",
    "\n",
    "    # Create and run a data processing Pipeline\n",
    "    data_prep_pipeline = Pipeline(stages=[tokenizer, stopRemove, hashingTF, idf, clean_up])\n",
    "\n",
    "    # Fit and transform the pipeline\n",
    "    cleaner = data_prep_pipeline.fit(data_df)\n",
    "    cleaned = cleaner.transform(data_df)\n",
    "\n",
    "    # Load the saved NaiveBayes Classifier\n",
    "    #nb = NaiveBayes.load(\"static/resources/nb\")\n",
    "\n",
    "    #Restored the trained predictor (Trained on 1 mil tweets)\n",
    "    #predictor = NaiveBayesModel.load(\"static/resources/nb_model\")\n",
    "\n",
    "    #Predict the sentiment of the text using the restored predictor\n",
    "    test_results = predictor.transform(cleaned)\n",
    "\n",
    "    df = test_results.select(\"text\", \"tag\", \"prediction\", \"probability\").toPandas()\n",
    "    \n",
    "    positive_score = [prob[1] for prob in df['probability']]\n",
    "    df['probability'] = positive_score\n",
    "\n",
    "    percents = [\"{:.2%}\".format(prob) for prob in df['probability']]\n",
    "    df['percent'] = percents\n",
    "\n",
    "    df.loc[df['prediction'] == 1.0, 'prediction'] = 'Positive'\n",
    "    df.loc[df['prediction'] == 0.0, 'prediction'] = 'Negative'\n",
    "\n",
    "    top_10 = df.sort_values(by=['probability'], ascending=False).head(10)\n",
    "    bottom_10 = df.sort_values(by=['probability'], ascending=True).head(10)\n",
    "    \n",
    "    return(df, top_10, bottom_10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Tweets: 25\n",
      "rules: type: {\"rules\" : [{\"value\": \"Apple -is:retweet lang:en -has:links -has:media\", \"tag\": \"Apple\"},{\"value\": \"#WWDC22 -is:retweet lang:en -has:links -has:media\", \"tag\": \"#WWDC22\"},{\"value\": \"#LoveIsland -is:retweet lang:en -has:links -has:media\", \"tag\": \"#LoveIsland\"},{\"value\": \"Proud Boys -is:retweet lang:en -has:links -has:media\", \"tag\": \"Proud Boys\"},{\"value\": \"iOS 16 -is:retweet lang:en -has:links -has:media\", \"tag\": \"iOS 16\"},{\"value\": \"Aaron Donald -is:retweet lang:en -has:links -has:media\", \"tag\": \"Aaron Donald\"},{\"value\": \"Wilbur -is:retweet lang:en -has:links -has:media\", \"tag\": \"Wilbur\"},{\"value\": \"Giant Bomb -is:retweet lang:en -has:links -has:media\", \"tag\": \"Giant Bomb\"},{\"value\": \"Jocelyn Alo -is:retweet lang:en -has:links -has:media\", \"tag\": \"Jocelyn Alo\"},{\"value\": \"Michigan -is:retweet lang:en -has:links -has:media\", \"tag\": \"Michigan\"}]}\n",
      "get_rules() response:\n",
      "{\"data\": [{\"id\": \"1533945829374889985\", \"value\": \"Giant Bomb -is:retweet lang:en -has:links -has:media\", \"tag\": \"Giant Bomb\"}, {\"id\": \"1533945829374889986\", \"value\": \"Michigan -is:retweet lang:en -has:links -has:media\", \"tag\": \"Michigan\"}, {\"id\": \"1533945829374889987\", \"value\": \"#WWDC22 -is:retweet lang:en -has:links -has:media\", \"tag\": \"#WWDC22\"}, {\"id\": \"1533945829374889988\", \"value\": \"Jocelyn Alo -is:retweet lang:en -has:links -has:media\", \"tag\": \"Jocelyn Alo\"}, {\"id\": \"1533945829374889989\", \"value\": \"iOS 16 -is:retweet lang:en -has:links -has:media\", \"tag\": \"iOS 16\"}, {\"id\": \"1533945829374889990\", \"value\": \"Aaron Donald -is:retweet lang:en -has:links -has:media\", \"tag\": \"Aaron Donald\"}, {\"id\": \"1533945829374889991\", \"value\": \"#LoveIsland -is:retweet lang:en -has:links -has:media\", \"tag\": \"#LoveIsland\"}, {\"id\": \"1533945829374889992\", \"value\": \"Proud Boys -is:retweet lang:en -has:links -has:media\", \"tag\": \"Proud Boys\"}, {\"id\": \"1533945829374889993\", \"value\": \"Wilbur -is:retweet lang:en -has:links -has:media\", \"tag\": \"Wilbur\"}, {\"id\": \"1533945829374889994\", \"value\": \"Apple -is:retweet lang:en -has:links -has:media\", \"tag\": \"Apple\"}], \"meta\": {\"sent\": \"2022-06-06T22:56:46.373Z\", \"result_count\": 10}}\n",
      "delete_all_rules(rules) response:\n",
      "assigning specified rules\n",
      "set_rules(delete) response:\n",
      "{\"data\": [{\"value\": \"iOS 16 -is:retweet lang:en -has:links -has:media\", \"tag\": \"iOS 16\", \"id\": \"1533946026582716417\"}, {\"value\": \"Michigan -is:retweet lang:en -has:links -has:media\", \"tag\": \"Michigan\", \"id\": \"1533946026582716425\"}, {\"value\": \"Proud Boys -is:retweet lang:en -has:links -has:media\", \"tag\": \"Proud Boys\", \"id\": \"1533946026582716426\"}, {\"value\": \"Apple -is:retweet lang:en -has:links -has:media\", \"tag\": \"Apple\", \"id\": \"1533946026582716418\"}, {\"value\": \"Wilbur -is:retweet lang:en -has:links -has:media\", \"tag\": \"Wilbur\", \"id\": \"1533946026582716422\"}, {\"value\": \"#LoveIsland -is:retweet lang:en -has:links -has:media\", \"tag\": \"#LoveIsland\", \"id\": \"1533946026582716423\"}, {\"value\": \"Jocelyn Alo -is:retweet lang:en -has:links -has:media\", \"tag\": \"Jocelyn Alo\", \"id\": \"1533946026582716419\"}, {\"value\": \"Giant Bomb -is:retweet lang:en -has:links -has:media\", \"tag\": \"Giant Bomb\", \"id\": \"1533946026582716420\"}, {\"value\": \"Aaron Donald -is:retweet lang:en -has:links -has:media\", \"tag\": \"Aaron Donald\", \"id\": \"1533946026582716421\"}, {\"value\": \"#WWDC22 -is:retweet lang:en -has:links -has:media\", \"tag\": \"#WWDC22\", \"id\": \"1533946026582716424\"}], \"meta\": {\"sent\": \"2022-06-06T22:56:46.758Z\", \"summary\": {\"created\": 10, \"not_created\": 0, \"valid\": 10, \"invalid\": 0}}}\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import tostring\n",
    "from flask import Flask, render_template, redirect, url_for, request, session\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "#pull the rules from the textarea input box\n",
    "rules = '{\"rules\" : [{\"value\": \"Apple -is:retweet lang:en -has:links -has:media\", \"tag\": \"Apple\"},{\"value\": \"#WWDC22 -is:retweet lang:en -has:links -has:media\", \"tag\": \"#WWDC22\"},{\"value\": \"#LoveIsland -is:retweet lang:en -has:links -has:media\", \"tag\": \"#LoveIsland\"},{\"value\": \"Proud Boys -is:retweet lang:en -has:links -has:media\", \"tag\": \"Proud Boys\"},{\"value\": \"iOS 16 -is:retweet lang:en -has:links -has:media\", \"tag\": \"iOS 16\"},{\"value\": \"Aaron Donald -is:retweet lang:en -has:links -has:media\", \"tag\": \"Aaron Donald\"},{\"value\": \"Wilbur -is:retweet lang:en -has:links -has:media\", \"tag\": \"Wilbur\"},{\"value\": \"Giant Bomb -is:retweet lang:en -has:links -has:media\", \"tag\": \"Giant Bomb\"},{\"value\": \"Jocelyn Alo -is:retweet lang:en -has:links -has:media\", \"tag\": \"Jocelyn Alo\"},{\"value\": \"Michigan -is:retweet lang:en -has:links -has:media\", \"tag\": \"Michigan\"}]}'\n",
    "\n",
    "#pull the number of Tweets to request from the Twitter API\n",
    "countOfTweets = 25\n",
    "print(f'Count of Tweets: {str(countOfTweets)}')\n",
    "if countOfTweets is None:\n",
    "    countOfTweets = 10\n",
    "\n",
    "print('rules: type: ' + rules)\n",
    "\n",
    "#Perform the steps needed to receive the twitter stream\n",
    "\n",
    "rules = json.loads(rules)\n",
    "#get the previous rules\n",
    "old_rules = get_rules()\n",
    "\n",
    "#delete the previous rules\n",
    "delete = delete_all_rules(old_rules)\n",
    "\n",
    "#set the rules to be the new rules\n",
    "set = set_rules(rules[\"rules\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "tweets streamed: 1\n",
      "tweets streamed: 2\n",
      "tweets streamed: 3\n",
      "tweets streamed: 4\n",
      "tweets streamed: 5\n",
      "tweets streamed: 6\n",
      "tweets streamed: 7\n",
      "tweets streamed: 8\n",
      "tweets streamed: 9\n",
      "tweets streamed: 10\n",
      "tweets streamed: 11\n",
      "tweets streamed: 12\n",
      "tweets streamed: 13\n",
      "tweets streamed: 14\n",
      "tweets streamed: 15\n",
      "tweets streamed: 16\n",
      "tweets streamed: 17\n",
      "tweets streamed: 18\n",
      "tweets streamed: 19\n",
      "tweets streamed: 20\n",
      "tweets streamed: 21\n",
      "tweets streamed: 22\n",
      "tweets streamed: 23\n",
      "tweets streamed: 24\n",
      "tweets streamed: 25\n"
     ]
    }
   ],
   "source": [
    "#Start the twitter stream with the requested rule set\n",
    "tweet_list = get_stream(countOfTweets) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/06 16:15:07 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n"
     ]
    }
   ],
   "source": [
    "#Send the collected twitter feed to the machine learning model\n",
    "eval_list, top_10, bottom_10 = eval_text_list(tweet_list)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PalmerReport I look forward to Stone and Jone...</td>\n",
       "      <td>Proud Boys</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@VoidBurger I loved following Jeff on GB but y...</td>\n",
       "      <td>Giant Bomb</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Since the head of the Proud boys was seen in t...</td>\n",
       "      <td>Proud Boys</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>99.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@duty2warn Biden: 81,282,916\\nTrump:74,223,369</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.988073</td>\n",
       "      <td>98.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple shares are trading higher in anticipati...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.981373</td>\n",
       "      <td>98.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thurrott Maybe they should make two keynotes....</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.853507</td>\n",
       "      <td>85.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iOS 16 is gonna be </td>\n",
       "      <td>iOS 16</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.599124</td>\n",
       "      <td>59.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@Ahmed_UTC2 @BrachatJan @jenni_moyer @NoContex...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.392138</td>\n",
       "      <td>39.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@twostraws Where is info of SWIFTUI 4.0?</td>\n",
       "      <td>#WWDC22</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.250873</td>\n",
       "      <td>25.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The NCAA is a joke with that call against Mich...</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.068226</td>\n",
       "      <td>6.82%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text         tag prediction  \\\n",
       "1   @PalmerReport I look forward to Stone and Jone...  Proud Boys   Positive   \n",
       "14  @VoidBurger I loved following Jeff on GB but y...  Giant Bomb   Positive   \n",
       "11  Since the head of the Proud boys was seen in t...  Proud Boys   Positive   \n",
       "15     @duty2warn Biden: 81,282,916\\nTrump:74,223,369    Michigan   Positive   \n",
       "4   Apple shares are trading higher in anticipati...       Apple   Positive   \n",
       "0   @thurrott Maybe they should make two keynotes....       Apple   Positive   \n",
       "16                               iOS 16 is gonna be       iOS 16   Positive   \n",
       "24  @Ahmed_UTC2 @BrachatJan @jenni_moyer @NoContex...       Apple   Negative   \n",
       "21           @twostraws Where is info of SWIFTUI 4.0?     #WWDC22   Negative   \n",
       "9   The NCAA is a joke with that call against Mich...    Michigan   Negative   \n",
       "\n",
       "    probability  percent  \n",
       "1      1.000000  100.00%  \n",
       "14     0.999999  100.00%  \n",
       "11     0.999673   99.97%  \n",
       "15     0.988073   98.81%  \n",
       "4      0.981373   98.14%  \n",
       "0      0.853507   85.35%  \n",
       "16     0.599124   59.91%  \n",
       "24     0.392138   39.21%  \n",
       "21     0.250873   25.09%  \n",
       "9      0.068226    6.82%  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the returned eval_list\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PalmerReport I look forward to Stone and Jone...</td>\n",
       "      <td>Proud Boys</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@VoidBurger I loved following Jeff on GB but y...</td>\n",
       "      <td>Giant Bomb</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Since the head of the Proud boys was seen in t...</td>\n",
       "      <td>Proud Boys</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>99.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@duty2warn Biden: 81,282,916\\nTrump:74,223,369</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.988073</td>\n",
       "      <td>98.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple shares are trading higher in anticipati...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.981373</td>\n",
       "      <td>98.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thurrott Maybe they should make two keynotes....</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.853507</td>\n",
       "      <td>85.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iOS 16 is gonna be </td>\n",
       "      <td>iOS 16</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.599124</td>\n",
       "      <td>59.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@Ahmed_UTC2 @BrachatJan @jenni_moyer @NoContex...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.392138</td>\n",
       "      <td>39.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@twostraws Where is info of SWIFTUI 4.0?</td>\n",
       "      <td>#WWDC22</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.250873</td>\n",
       "      <td>25.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The NCAA is a joke with that call against Mich...</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.068226</td>\n",
       "      <td>6.82%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text         tag prediction  \\\n",
       "1   @PalmerReport I look forward to Stone and Jone...  Proud Boys   Positive   \n",
       "14  @VoidBurger I loved following Jeff on GB but y...  Giant Bomb   Positive   \n",
       "11  Since the head of the Proud boys was seen in t...  Proud Boys   Positive   \n",
       "15     @duty2warn Biden: 81,282,916\\nTrump:74,223,369    Michigan   Positive   \n",
       "4   Apple shares are trading higher in anticipati...       Apple   Positive   \n",
       "0   @thurrott Maybe they should make two keynotes....       Apple   Positive   \n",
       "16                               iOS 16 is gonna be       iOS 16   Positive   \n",
       "24  @Ahmed_UTC2 @BrachatJan @jenni_moyer @NoContex...       Apple   Negative   \n",
       "21           @twostraws Where is info of SWIFTUI 4.0?     #WWDC22   Negative   \n",
       "9   The NCAA is a joke with that call against Mich...    Michigan   Negative   \n",
       "\n",
       "    probability  percent  \n",
       "1      1.000000  100.00%  \n",
       "14     0.999999  100.00%  \n",
       "11     0.999673   99.97%  \n",
       "15     0.988073   98.81%  \n",
       "4      0.981373   98.14%  \n",
       "0      0.853507   85.35%  \n",
       "16     0.599124   59.91%  \n",
       "24     0.392138   39.21%  \n",
       "21     0.250873   25.09%  \n",
       "9      0.068226    6.82%  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzvGp6NTcu/0J5KsIw7QPb",
   "collapsed_sections": [],
   "name": "Sentiment_Analysis_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlenv2",
   "language": "python",
   "name": "mlenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
